# Classroom_assistant
# ğŸ§  AI-Powered Interactive Learning Assistant for Classrooms

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.9%2B-green)
![Status](https://img.shields.io/badge/status-Active-brightgreen)

> A lightweight, offline-capable AI teaching assistant that listens to your questions â€” and explains them like a friendly tutor.

---

## ğŸš€ Features

- ğŸ¤ Voice and ğŸ’¬ text input support
- ğŸ§‘â€ğŸ« Educational, student-friendly answers
- ğŸ§  Uses `flan-alpaca-base` for question-answering
- ğŸ§© Modular design (easy to plug in face/visual input)
- ğŸ›‘ Smart fallback when model is unsure
- ğŸ’» Runs on low-resource systems (8GB RAM)

---

## ğŸ“Œ Problem Statement

Modern classrooms lack personalized, real-time help. Students hesitate to ask questions, and teachers can't address everyone. This assistant provides:
- 24/7 intelligent support
- Multimodal input (voice/text)
- Clear, accurate explanations
- Room for future emotion/visual feedback

---

## ğŸ§° Technologies Used

| Component | Tool |
|----------|------|
| NLP Model | [`declare-lab/flan-alpaca-base`](https://huggingface.co/declare-lab/flan-alpaca-base) |
| Framework | Hugging Face Transformers, PyTorch |
| Voice Input | Python SpeechRecognition |
| Interface | Terminal-based (CLI) |
| System Requirements | Python 3.9+, 8 GB RAM, microphone |

---

<pre lang="text"><code>## ğŸ“ Project Structure ```text . â”œâ”€â”€ assistant/ # Core assistant modules â”‚ â”œâ”€â”€ core.py # Main logic controller â”‚ â”œâ”€â”€ models.py # Model loading & response generation â”‚ â”œâ”€â”€ interface.py # UI logic (CLI or future GUI) â”‚ â”œâ”€â”€ engagement.py # Engagement analysis (optional/extendable) â”œâ”€â”€ main.py # Entry point â”œâ”€â”€ requirements.txt # Project dependencies â”œâ”€â”€ .gitignore # Ignored files/folders â”œâ”€â”€ README.md # Project documentation â”œâ”€â”€ ai_config.json # Model config (optional) â”œâ”€â”€ student_profile.json # Student customization (optional) â”œâ”€â”€ demo_screenshot.png # Demo image â”œâ”€â”€ docs/ # Documentation, PPTs, reports (optional) â”‚ â”œâ”€â”€ AI_Assistant_Report.docx â”‚ â””â”€â”€ AI_Assistant_Presentation.pptx ``` </code></pre>

---

## ğŸ‘¨â€ğŸ’» Contributors

| Name             | Role                         | GitHub Username     |
|------------------|------------------------------|---------------------|
| Dharun A         | Lead Developer, Integrator   | `@dharun-anandhan`  |
| Saravanakumar B  | Voice Input, UI Integration  | `@teammate1username`|
| Rahul Ramana V   | Testing, Debugging, Docs     | `@teammate2username`|

---

## ğŸ“· Demo Screenshot

![Screenshot](demo_screenshot.png)

---

## ğŸ¬ Demo Video

> ğŸ”— Coming Soon: Add YouTube/GDrive link after uploading

---

## ğŸ› ï¸ How to Run

```bash
# 1. Clone the repo
git clone https://github.com/your-username/classroom-assistant.git
cd classroom-assistant

# 2. Create virtual environment
python -m venv classroom_env
source classroom_env/bin/activate  # Or use Scripts\\activate on Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the assistant
python main.py

